---
title: Data Aggregation
author: Michael Fuchs
date: '2021-03-26'
slug: data-aggregation
categories: []
tags: []
output:
  blogdown::html_page:
    toc: true
    toc_depth: 5
---


# 1 Introduction

Now that we have got to know the best-known methods from the field of [Data Wrangling](https://michael-fuchs-sql.netlify.app/2021/03/23/data-wrangling/), we come to the possibilities of Data Aggregation. 

For this post I used the dataset *flight* from the statistics platform ["Kaggle"](https://www.kaggle.com). You can download it from my [GitHub Repository](https://github.com/MFuchs1989/Datasets-and-Miscellaneous/tree/main/datasets).


# 2 Preparation

For the following examples, I set up a new database. 

```{r, eval=F, echo=T}
SET LANGUAGE ENGLISH


CREATE DATABASE Aggregation;

USE Aggregation;
```

I now import the record *flight* into this database ('Aggregation'). I have described how to do this [here](https://michael-fuchs-sql.netlify.app/2021/03/20/read-and-write-to-files/#via-ssms).
**Tip**: Pay attention to the data types assigned to the columns. For example, Dep_Delay is stored as nvchar by default. Change all data types accordingly. 


Furthermore, I create a table that contains NULL values among other things:


```{r, eval=F, echo=T}
CREATE TABLE example_Table
    (ID INT NOT NULL IDENTITY(1,1) PRIMARY KEY,
    Cat1 VARCHAR(100),
    Cat2 INT)
    ;

INSERT INTO example_Table (Cat1, Cat2) VALUES ('A', 1)
INSERT INTO example_Table (Cat1, Cat2) VALUES ('A', 2)
INSERT INTO example_Table (Cat1, Cat2) VALUES ('A', NULL)

INSERT INTO example_Table (Cat1, Cat2) VALUES ('B', 1)
INSERT INTO example_Table (Cat1, Cat2) VALUES ('B', 2)
INSERT INTO example_Table (Cat1, Cat2) VALUES ('B', 3)
INSERT INTO example_Table (Cat1, Cat2) VALUES (NULL, 4)
INSERT INTO example_Table (Cat1, Cat2) VALUES ('B', NULL)
INSERT INTO example_Table (Cat1, Cat2) VALUES ('B', NULL)
```



# 3 Data Aggregation

In the following, I will present the best-known aggregation techniques. 


## 3.1 Count


For the examples with Count, let's first look at the example table that was created:

```{r, eval=F, echo=T}
SELECT *
	FROM example_Table
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p1.png)

As we know from the post [Data Wrangling](https://michael-fuchs-sql.netlify.app/2021/03/23/data-wrangling/) from chapter [Count Rows](https://michael-fuchs-sql.netlify.app/2021/03/23/data-wrangling/#count-rows), with the following SELECT COUNT command we have the possibility to determine how many rows the data set contains in total. It does not matter whether some columns contain NULL values or not. 

```{r, eval=F, echo=T}
SELECT COUNT(*) AS num_observations
	FROM example_Table
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p2.png)


The method of counting the primary key is just as safe, since it must not contain any NULL values. 

```{r, eval=F, echo=T}
SELECT COUNT(ID) AS num_observations
	FROM example_Table
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p3.png)


Now let's count the observations in column Cat1:

```{r, eval=F, echo=T}
SELECT COUNT(Cat1) AS num_observations_Cat1
	FROM example_Table
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p4.png)

And now the one from Cat2:

```{r, eval=F, echo=T}
SELECT COUNT(Cat2) AS num_observations_Cat2
	FROM example_Table
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p5.png)

The results fit because we have one NULL value in Cat1 and two in Cat2.

I have described [here how to specifically filter NULL values](https://michael-fuchs-sql.netlify.app/2021/03/23/data-wrangling/#filter-for-null-values). This way you don't have to do the workaround and compare the number of counted rows of a column with the counted rows of the primary key to determine if and how many NULL values are contained. 



## 3.2 Sum

Next we will deal with the SUM function. As the name suggests, we can get the sum of a numeric column. 

In the following I will continue to work with the loaded data set *flight*. 
Here, for example, I would like to have the sum of the flight distances travelled output:


```{r, eval=F, echo=T}
SELECT SUM(Distance) AS sum_distance
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p6.png)

Ok the output doesn't look very pretty yet. So I'll have it output in thousands next:


```{r, eval=F, echo=T}
SELECT SUM(Distance)/1000 AS sum_distance_in_thousand
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p7.png)

Perfect. If I also want to have the number of the underlying observations displayed, I can also use the COUNT command shown above.

```{r, eval=F, echo=T}
SELECT COUNT(*) AS num_departures, 
	   SUM(Distance)/1000 AS sum_distance_in_thousand
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p8.png)

If I do not yet have metrics, such as the planned travel time in my data set, available as a separate column, I can also perform this calculation operation within the SELECT statement without having to modify the original table.


```{r, eval=F, echo=T}
SELECT SUM(Scheduled_Arrival - Scheduled_Departure) AS scheduled_travel_time
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p9.png)


## 3.3 Min, Max and Average

Just like the sum of a column, we can also output the minimum, maximum or average of a numerical column. 

For now, let's focus only on the Dep_Delay column, which shows the difference between the planned and the actual departure time. 


With MIN we get the highest time an aircraft has taken off before the scheduled departure time. 

```{r, eval=F, echo=T}
SELECT MIN(Dep_Delay) AS min_dep_delay
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p10.png)

MAX is the latest time an aircraft has taken off after the scheduled take-off time. 

```{r, eval=F, echo=T}
SELECT MAX(Dep_Delay) AS max_dep_delay
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p11.png)


With AVG as already suspected, we get the average delay of all departures.

```{r, eval=F, echo=T}
SELECT AVG(Dep_Delay) AS avg_dep_delay
	FROM flight
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p12.png)



## 3.4 Group By

Now we come to the probably most used aggregation function: Group By. 
All of the functions that we have learned about before can be used here and only really develop their added value with Group By. 

With the Group By command, we can have values, such as the mean value, output in groups. 


### 3.4.1 Simple Group By with AVG

Let's take a look at the average delay of departures grouped by originating airports. 


```{r, eval=F, echo=T}
SELECT Origin_Airport, 
	   AVG(Dep_Delay) AS avg_dep_delay
	FROM flight
	GROUP BY Origin_Airport
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p14.png)

In order for this select statement to work, when using the Group By function, you must ensure that the column after which the grouping takes place is also output as a column (after the SELECT command). 


### 3.4.2 Group and Order By with AVG

After the previously shown output is still a bit confused, I use the ORDER BY command in the following statement to have the departure airports output in alphabetical order. 


```{r, eval=F, echo=T}
SELECT Origin_Airport, 
	   AVG(Dep_Delay) AS avg_dep_delay
	FROM flight
	GROUP BY Origin_Airport
	ORDER BY Origin_Airport
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p15.png)


### 3.4.3 Group and Order By with ABS & STDEV

What is also always good to have a measure of position as it is the average value of a measure of dispersion output. 
Therefore, for the same grouping, I also look at the absolute values behind the groupings and their standard deviation. 

```{r, eval=F, echo=T}
SELECT Origin_Airport, 
	   COUNT(*) AS num_departures,
	   STDEV(Dep_Delay) AS st_dev_dep_delay
	FROM flight
	GROUP BY Origin_Airport
	ORDER BY Origin_Airport
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p16.png)

Now I no longer order by Origin_Airport but by the number of absolute values.  


```{r, eval=F, echo=T}
SELECT Origin_Airport, 
	   COUNT(*) AS num_departures,
	   STDEV(Dep_Delay) AS st_dev_dep_delay
	FROM flight
	GROUP BY Origin_Airport
	ORDER BY num_departures DESC
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p17.png)

### 3.4.4 Group and Order By with MAX

Let's take a look at the highest value recorded for each group (Origin_Airport). 

```{r, eval=F, echo=T}
SELECT Origin_Airport, 
	   max(Dep_Delay) AS max_dep_delay
	FROM flight
	GROUP BY Origin_Airport
	ORDER BY max_dep_delay DESC
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p18.png)


### 3.4.5 Multiple Group and Order By

Of course, we also have the possibility to use multiple Group By and Order By. 
Let's have a look at the absolute numbers of departures grouped by Origin_Airport and DayOfWeek. 


```{r, eval=F, echo=T}
SELECT Origin_Airport, DayOfWeek,
	   COUNT(*) AS num_departures
	FROM flight
	GROUP BY Origin_Airport, DayOfWeek
	ORDER BY Origin_Airport, DayOfWeek
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p19.png)


## 3.5 Having

As we can see from the last output by the multiple grouping, quite a few lines are generated quite quickly. Often not all rows are relevant but only those that exceed a certain threshold. 
We can set this threshold using the HAVING command. 

In the following I want to have only the absolute values of the departures grouped by Origin_Airport and DayOfWeek that exceed the number 100. 
Means in our example if a weekday of a departure airport has less than 100 departures it should not be displayed at all. 


```{r, eval=F, echo=T}
SELECT Origin_Airport, DayOfWeek,
	   COUNT(*) AS num_departures
	FROM flight
	GROUP BY Origin_Airport, DayOfWeek
	HAVING COUNT(*) > 100
	ORDER BY Origin_Airport, DayOfWeek
	;
```

![](/post/2021-03-26-data-aggregation_files/p10p20.png)

And already we have a clear output of only 21 observations. 



# 4 Conclusion

In this post I showed how to use data aggregation techniques to generate profitable comparisons of values. 






